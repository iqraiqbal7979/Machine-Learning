{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2ae685",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb01835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51dbeb",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c503744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (mean)</th>\n",
       "      <th>Texture (mean)</th>\n",
       "      <th>Perimeter (mean)</th>\n",
       "      <th>Area (mean)</th>\n",
       "      <th>Smoothness (mean)</th>\n",
       "      <th>Compactness (mean)</th>\n",
       "      <th>Concavity (mean)</th>\n",
       "      <th>Concave points (mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (worst)</th>\n",
       "      <th>Texture (worst)</th>\n",
       "      <th>Perimeter (worst)</th>\n",
       "      <th>Area (worst)</th>\n",
       "      <th>Smoothness (worst)</th>\n",
       "      <th>Compactness (worst)</th>\n",
       "      <th>Concavity (worst)</th>\n",
       "      <th>Concave points (worst)</th>\n",
       "      <th>Symmetry (worst)</th>\n",
       "      <th>Fractal dimension (worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854941</td>\n",
       "      <td>B</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85713702</td>\n",
       "      <td>B</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926125</td>\n",
       "      <td>M</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id Diagnosis  Radius (mean)  Texture (mean)  Perimeter (mean)  \\\n",
       "0     8510426         B         13.540           14.36             87.46   \n",
       "1     8510653         B         13.080           15.71             85.63   \n",
       "2     8510824         B          9.504           12.44             60.34   \n",
       "3      854941         B         13.030           18.42             82.61   \n",
       "4    85713702         B          8.196           16.84             51.71   \n",
       "..        ...       ...            ...             ...               ...   \n",
       "564    926125         M         20.920           25.09            143.00   \n",
       "565    926424         M         21.560           22.39            142.00   \n",
       "566    926682         M         20.130           28.25            131.20   \n",
       "567    926954         M         16.600           28.08            108.30   \n",
       "568    927241         M         20.600           29.33            140.10   \n",
       "\n",
       "     Area (mean)  Smoothness (mean)  Compactness (mean)  Concavity (mean)  \\\n",
       "0          566.3            0.09779             0.08129           0.06664   \n",
       "1          520.0            0.10750             0.12700           0.04568   \n",
       "2          273.9            0.10240             0.06492           0.02956   \n",
       "3          523.8            0.08983             0.03766           0.02562   \n",
       "4          201.9            0.08600             0.05943           0.01588   \n",
       "..           ...                ...                 ...               ...   \n",
       "564       1347.0            0.10990             0.22360           0.31740   \n",
       "565       1479.0            0.11100             0.11590           0.24390   \n",
       "566       1261.0            0.09780             0.10340           0.14400   \n",
       "567        858.1            0.08455             0.10230           0.09251   \n",
       "568       1265.0            0.11780             0.27700           0.35140   \n",
       "\n",
       "     Concave points (mean)  ...  Radius (worst)  Texture (worst)  \\\n",
       "0                 0.047810  ...          15.110            19.26   \n",
       "1                 0.031100  ...          14.500            20.49   \n",
       "2                 0.020760  ...          10.230            15.66   \n",
       "3                 0.029230  ...          13.300            22.81   \n",
       "4                 0.005917  ...           8.964            21.96   \n",
       "..                     ...  ...             ...              ...   \n",
       "564               0.147400  ...          24.290            29.41   \n",
       "565               0.138900  ...          25.450            26.40   \n",
       "566               0.097910  ...          23.690            38.25   \n",
       "567               0.053020  ...          18.980            34.12   \n",
       "568               0.152000  ...          25.740            39.42   \n",
       "\n",
       "     Perimeter (worst)  Area (worst)  Smoothness (worst)  Compactness (worst)  \\\n",
       "0                99.70         711.2             0.14400              0.17730   \n",
       "1                96.09         630.5             0.13120              0.27760   \n",
       "2                65.13         314.9             0.13240              0.11480   \n",
       "3                84.46         545.9             0.09701              0.04619   \n",
       "4                57.26         242.2             0.12970              0.13570   \n",
       "..                 ...           ...                 ...                  ...   \n",
       "564             179.10        1819.0             0.14070              0.41860   \n",
       "565             166.10        2027.0             0.14100              0.21130   \n",
       "566             155.00        1731.0             0.11660              0.19220   \n",
       "567             126.70        1124.0             0.11390              0.30940   \n",
       "568             184.60        1821.0             0.16500              0.86810   \n",
       "\n",
       "     Concavity (worst)  Concave points (worst)  Symmetry (worst)  \\\n",
       "0              0.23900                 0.12880            0.2977   \n",
       "1              0.18900                 0.07283            0.3184   \n",
       "2              0.08867                 0.06227            0.2450   \n",
       "3              0.04833                 0.05013            0.1987   \n",
       "4              0.06880                 0.02564            0.3105   \n",
       "..                 ...                     ...               ...   \n",
       "564            0.65990                 0.25420            0.2929   \n",
       "565            0.41070                 0.22160            0.2060   \n",
       "566            0.32150                 0.16280            0.2572   \n",
       "567            0.34030                 0.14180            0.2218   \n",
       "568            0.93870                 0.26500            0.4087   \n",
       "\n",
       "     Fractal dimension (worst)  \n",
       "0                      0.07259  \n",
       "1                      0.08183  \n",
       "2                      0.07773  \n",
       "3                      0.06169  \n",
       "4                      0.07409  \n",
       "..                         ...  \n",
       "564                    0.09873  \n",
       "565                    0.07115  \n",
       "566                    0.06637  \n",
       "567                    0.07820  \n",
       "568                    0.12400  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cancer.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2656b43d",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ecc37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    1\n",
       "Name: Diagnosis, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diagnosis']= df['Diagnosis'].map({'B': 0 , 'M': 1})\n",
    "Y= df['Diagnosis']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba04258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (mean)</th>\n",
       "      <th>Texture (mean)</th>\n",
       "      <th>Perimeter (mean)</th>\n",
       "      <th>Area (mean)</th>\n",
       "      <th>Smoothness (mean)</th>\n",
       "      <th>Compactness (mean)</th>\n",
       "      <th>Concavity (mean)</th>\n",
       "      <th>Concave points (mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (worst)</th>\n",
       "      <th>Texture (worst)</th>\n",
       "      <th>Perimeter (worst)</th>\n",
       "      <th>Area (worst)</th>\n",
       "      <th>Smoothness (worst)</th>\n",
       "      <th>Compactness (worst)</th>\n",
       "      <th>Concavity (worst)</th>\n",
       "      <th>Concave points (worst)</th>\n",
       "      <th>Symmetry (worst)</th>\n",
       "      <th>Fractal dimension (worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8510426</td>\n",
       "      <td>0</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8510653</td>\n",
       "      <td>0</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8510824</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854941</td>\n",
       "      <td>0</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85713702</td>\n",
       "      <td>0</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926125</td>\n",
       "      <td>1</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Diagnosis  Radius (mean)  Texture (mean)  Perimeter (mean)  \\\n",
       "0     8510426          0         13.540           14.36             87.46   \n",
       "1     8510653          0         13.080           15.71             85.63   \n",
       "2     8510824          0          9.504           12.44             60.34   \n",
       "3      854941          0         13.030           18.42             82.61   \n",
       "4    85713702          0          8.196           16.84             51.71   \n",
       "..        ...        ...            ...             ...               ...   \n",
       "564    926125          1         20.920           25.09            143.00   \n",
       "565    926424          1         21.560           22.39            142.00   \n",
       "566    926682          1         20.130           28.25            131.20   \n",
       "567    926954          1         16.600           28.08            108.30   \n",
       "568    927241          1         20.600           29.33            140.10   \n",
       "\n",
       "     Area (mean)  Smoothness (mean)  Compactness (mean)  Concavity (mean)  \\\n",
       "0          566.3            0.09779             0.08129           0.06664   \n",
       "1          520.0            0.10750             0.12700           0.04568   \n",
       "2          273.9            0.10240             0.06492           0.02956   \n",
       "3          523.8            0.08983             0.03766           0.02562   \n",
       "4          201.9            0.08600             0.05943           0.01588   \n",
       "..           ...                ...                 ...               ...   \n",
       "564       1347.0            0.10990             0.22360           0.31740   \n",
       "565       1479.0            0.11100             0.11590           0.24390   \n",
       "566       1261.0            0.09780             0.10340           0.14400   \n",
       "567        858.1            0.08455             0.10230           0.09251   \n",
       "568       1265.0            0.11780             0.27700           0.35140   \n",
       "\n",
       "     Concave points (mean)  ...  Radius (worst)  Texture (worst)  \\\n",
       "0                 0.047810  ...          15.110            19.26   \n",
       "1                 0.031100  ...          14.500            20.49   \n",
       "2                 0.020760  ...          10.230            15.66   \n",
       "3                 0.029230  ...          13.300            22.81   \n",
       "4                 0.005917  ...           8.964            21.96   \n",
       "..                     ...  ...             ...              ...   \n",
       "564               0.147400  ...          24.290            29.41   \n",
       "565               0.138900  ...          25.450            26.40   \n",
       "566               0.097910  ...          23.690            38.25   \n",
       "567               0.053020  ...          18.980            34.12   \n",
       "568               0.152000  ...          25.740            39.42   \n",
       "\n",
       "     Perimeter (worst)  Area (worst)  Smoothness (worst)  Compactness (worst)  \\\n",
       "0                99.70         711.2             0.14400              0.17730   \n",
       "1                96.09         630.5             0.13120              0.27760   \n",
       "2                65.13         314.9             0.13240              0.11480   \n",
       "3                84.46         545.9             0.09701              0.04619   \n",
       "4                57.26         242.2             0.12970              0.13570   \n",
       "..                 ...           ...                 ...                  ...   \n",
       "564             179.10        1819.0             0.14070              0.41860   \n",
       "565             166.10        2027.0             0.14100              0.21130   \n",
       "566             155.00        1731.0             0.11660              0.19220   \n",
       "567             126.70        1124.0             0.11390              0.30940   \n",
       "568             184.60        1821.0             0.16500              0.86810   \n",
       "\n",
       "     Concavity (worst)  Concave points (worst)  Symmetry (worst)  \\\n",
       "0              0.23900                 0.12880            0.2977   \n",
       "1              0.18900                 0.07283            0.3184   \n",
       "2              0.08867                 0.06227            0.2450   \n",
       "3              0.04833                 0.05013            0.1987   \n",
       "4              0.06880                 0.02564            0.3105   \n",
       "..                 ...                     ...               ...   \n",
       "564            0.65990                 0.25420            0.2929   \n",
       "565            0.41070                 0.22160            0.2060   \n",
       "566            0.32150                 0.16280            0.2572   \n",
       "567            0.34030                 0.14180            0.2218   \n",
       "568            0.93870                 0.26500            0.4087   \n",
       "\n",
       "     Fractal dimension (worst)  \n",
       "0                      0.07259  \n",
       "1                      0.08183  \n",
       "2                      0.07773  \n",
       "3                      0.06169  \n",
       "4                      0.07409  \n",
       "..                         ...  \n",
       "564                    0.09873  \n",
       "565                    0.07115  \n",
       "566                    0.06637  \n",
       "567                    0.07820  \n",
       "568                    0.12400  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35eeb6",
   "metadata": {},
   "source": [
    "# Data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064a350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius (mean)</th>\n",
       "      <th>Texture (mean)</th>\n",
       "      <th>Perimeter (mean)</th>\n",
       "      <th>Area (mean)</th>\n",
       "      <th>Smoothness (mean)</th>\n",
       "      <th>Compactness (mean)</th>\n",
       "      <th>Concavity (mean)</th>\n",
       "      <th>Concave points (mean)</th>\n",
       "      <th>Symmetry (mean)</th>\n",
       "      <th>Fractal dimension (mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (worst)</th>\n",
       "      <th>Texture (worst)</th>\n",
       "      <th>Perimeter (worst)</th>\n",
       "      <th>Area (worst)</th>\n",
       "      <th>Smoothness (worst)</th>\n",
       "      <th>Compactness (worst)</th>\n",
       "      <th>Concavity (worst)</th>\n",
       "      <th>Concave points (worst)</th>\n",
       "      <th>Symmetry (worst)</th>\n",
       "      <th>Fractal dimension (worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.05766</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.06503</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.06879</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Radius (mean)  Texture (mean)  Perimeter (mean)  Area (mean)  \\\n",
       "0           13.540           14.36             87.46        566.3   \n",
       "1           13.080           15.71             85.63        520.0   \n",
       "2            9.504           12.44             60.34        273.9   \n",
       "3           13.030           18.42             82.61        523.8   \n",
       "4            8.196           16.84             51.71        201.9   \n",
       "..             ...             ...               ...          ...   \n",
       "564         20.920           25.09            143.00       1347.0   \n",
       "565         21.560           22.39            142.00       1479.0   \n",
       "566         20.130           28.25            131.20       1261.0   \n",
       "567         16.600           28.08            108.30        858.1   \n",
       "568         20.600           29.33            140.10       1265.0   \n",
       "\n",
       "     Smoothness (mean)  Compactness (mean)  Concavity (mean)  \\\n",
       "0              0.09779             0.08129           0.06664   \n",
       "1              0.10750             0.12700           0.04568   \n",
       "2              0.10240             0.06492           0.02956   \n",
       "3              0.08983             0.03766           0.02562   \n",
       "4              0.08600             0.05943           0.01588   \n",
       "..                 ...                 ...               ...   \n",
       "564            0.10990             0.22360           0.31740   \n",
       "565            0.11100             0.11590           0.24390   \n",
       "566            0.09780             0.10340           0.14400   \n",
       "567            0.08455             0.10230           0.09251   \n",
       "568            0.11780             0.27700           0.35140   \n",
       "\n",
       "     Concave points (mean)  Symmetry (mean)  Fractal dimension (mean)  ...  \\\n",
       "0                 0.047810           0.1885                   0.05766  ...   \n",
       "1                 0.031100           0.1967                   0.06811  ...   \n",
       "2                 0.020760           0.1815                   0.06905  ...   \n",
       "3                 0.029230           0.1467                   0.05863  ...   \n",
       "4                 0.005917           0.1769                   0.06503  ...   \n",
       "..                     ...              ...                       ...  ...   \n",
       "564               0.147400           0.2149                   0.06879  ...   \n",
       "565               0.138900           0.1726                   0.05623  ...   \n",
       "566               0.097910           0.1752                   0.05533  ...   \n",
       "567               0.053020           0.1590                   0.05648  ...   \n",
       "568               0.152000           0.2397                   0.07016  ...   \n",
       "\n",
       "     Radius (worst)  Texture (worst)  Perimeter (worst)  Area (worst)  \\\n",
       "0            15.110            19.26              99.70         711.2   \n",
       "1            14.500            20.49              96.09         630.5   \n",
       "2            10.230            15.66              65.13         314.9   \n",
       "3            13.300            22.81              84.46         545.9   \n",
       "4             8.964            21.96              57.26         242.2   \n",
       "..              ...              ...                ...           ...   \n",
       "564          24.290            29.41             179.10        1819.0   \n",
       "565          25.450            26.40             166.10        2027.0   \n",
       "566          23.690            38.25             155.00        1731.0   \n",
       "567          18.980            34.12             126.70        1124.0   \n",
       "568          25.740            39.42             184.60        1821.0   \n",
       "\n",
       "     Smoothness (worst)  Compactness (worst)  Concavity (worst)  \\\n",
       "0               0.14400              0.17730            0.23900   \n",
       "1               0.13120              0.27760            0.18900   \n",
       "2               0.13240              0.11480            0.08867   \n",
       "3               0.09701              0.04619            0.04833   \n",
       "4               0.12970              0.13570            0.06880   \n",
       "..                  ...                  ...                ...   \n",
       "564             0.14070              0.41860            0.65990   \n",
       "565             0.14100              0.21130            0.41070   \n",
       "566             0.11660              0.19220            0.32150   \n",
       "567             0.11390              0.30940            0.34030   \n",
       "568             0.16500              0.86810            0.93870   \n",
       "\n",
       "     Concave points (worst)  Symmetry (worst)  Fractal dimension (worst)  \n",
       "0                   0.12880            0.2977                    0.07259  \n",
       "1                   0.07283            0.3184                    0.08183  \n",
       "2                   0.06227            0.2450                    0.07773  \n",
       "3                   0.05013            0.1987                    0.06169  \n",
       "4                   0.02564            0.3105                    0.07409  \n",
       "..                      ...               ...                        ...  \n",
       "564                 0.25420            0.2929                    0.09873  \n",
       "565                 0.22160            0.2060                    0.07115  \n",
       "566                 0.16280            0.2572                    0.06637  \n",
       "567                 0.14180            0.2218                    0.07820  \n",
       "568                 0.26500            0.4087                    0.12400  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['Diagnosis','Id'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00f3399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.354e+01, 1.436e+01, 8.746e+01, ..., 1.288e-01, 2.977e-01,\n",
       "        7.259e-02],\n",
       "       [1.308e+01, 1.571e+01, 8.563e+01, ..., 7.283e-02, 3.184e-01,\n",
       "        8.183e-02],\n",
       "       [9.504e+00, 1.244e+01, 6.034e+01, ..., 6.227e-02, 2.450e-01,\n",
       "        7.773e-02],\n",
       "       ...,\n",
       "       [2.013e+01, 2.825e+01, 1.312e+02, ..., 1.628e-01, 2.572e-01,\n",
       "        6.637e-02],\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xx= np.array(X)\n",
    "Xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8eb8d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yy =np.array(Y)\n",
    "Yy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd934e",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4205978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xx, Yy, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a99c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23c8d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [5, 10] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f425f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K = 5\n",
      "\n",
      "Training Metrics: Accuracy=0.85, Precision=0.84, Recall=0.81, F1-Score=0.80\n",
      "\n",
      "Validation Metrics: Accuracy=0.85, Precision=0.85, Recall=0.84, F1-Score=0.81\n",
      "\n",
      "\n",
      "K = 10\n",
      "\n",
      "Training Metrics: Accuracy=0.81, Precision=0.80, Recall=0.85, F1-Score=0.79\n",
      "\n",
      "Validation Metrics: Accuracy=0.78, Precision=0.78, Recall=0.84, F1-Score=0.76\n",
      "\n",
      "Test Set Metrics:\n",
      "Accuracy: 0.88\n",
      "Precision: 0.78\n",
      "Recall: 0.94\n",
      "F1-Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in k_values:\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    train_metrics = []\n",
    "    validation_metrics = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_k_train, X_k_val = X_train[train_index], X_train[val_index]\n",
    "        y_k_train, y_k_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model.fit(X_k_train, y_k_train)\n",
    "\n",
    "        y_k_train_pred = model.predict(X_k_train)\n",
    "        train_accuracy = accuracy_score(y_k_train, y_k_train_pred)\n",
    "        train_precision = precision_score(y_k_train, y_k_train_pred, zero_division=0)\n",
    "        train_recall = recall_score(y_k_train, y_k_train_pred, zero_division=0)\n",
    "        train_f1 = f1_score(y_k_train, y_k_train_pred, zero_division=0)\n",
    "        train_metrics.append([train_accuracy, train_precision, train_recall, train_f1])\n",
    "\n",
    "        y_k_val_pred = model.predict(X_k_val)\n",
    "        val_accuracy = accuracy_score(y_k_val, y_k_val_pred)\n",
    "        val_precision = precision_score(y_k_val, y_k_val_pred, zero_division=0)\n",
    "        val_recall = recall_score(y_k_val, y_k_val_pred, zero_division=0)\n",
    "        val_f1 = f1_score(y_k_val, y_k_val_pred, zero_division=0)\n",
    "        validation_metrics.append([val_accuracy, val_precision, val_recall, val_f1])\n",
    "\n",
    "    train_metrics_mean = np.mean(train_metrics, axis=0)\n",
    "    validation_metrics_mean = np.mean(validation_metrics, axis=0)\n",
    "\n",
    "    print('\\n')\n",
    "    print(f\"K = {k}\")\n",
    "    print(f\"\\nTraining Metrics: Accuracy={train_metrics_mean[0]:.2f}, Precision={train_metrics_mean[1]:.2f}, Recall={train_metrics_mean[2]:.2f}, F1-Score={train_metrics_mean[3]:.2f}\")\n",
    "    print(f\"\\nValidation Metrics: Accuracy={validation_metrics_mean[0]:.2f}, Precision={validation_metrics_mean[1]:.2f}, Recall={validation_metrics_mean[2]:.2f}, F1-Score={validation_metrics_mean[3]:.2f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Precision: {test_precision:.2f}\")\n",
    "print(f\"Recall: {test_recall:.2f}\")\n",
    "print(f\"F1-Score: {test_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd96e2",
   "metadata": {},
   "source": [
    "# Question no 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24650e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a73361f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer.csv')\n",
    "df['Diagnosis'] = df['Diagnosis'].map({'B': 0, 'M': 1})\n",
    "\n",
    "Y = df['Diagnosis']\n",
    "X = df.drop(columns=['Diagnosis', 'Id'])\n",
    "\n",
    "Xx = np.array(X)\n",
    "Yy = np.array(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a4b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xx, Yy, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495e6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d0a25a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 5 (Logistic Regression)\n",
      "Training Metrics: Accuracy=0.96, Precision=0.96, Recall=0.94, F1-Score=0.95\n",
      "Validation Metrics: Accuracy=0.95, Precision=0.96, Recall=0.90, F1-Score=0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 10 (Logistic Regression)\n",
      "Training Metrics: Accuracy=0.96, Precision=0.96, Recall=0.94, F1-Score=0.95\n",
      "Validation Metrics: Accuracy=0.95, Precision=0.95, Recall=0.92, F1-Score=0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation for Logistic Regression\n",
    "k_values = [5, 10]\n",
    "\n",
    "for k in k_values:\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    train_metrics = []\n",
    "    validation_metrics = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_k_train, X_k_val = X_train[train_index], X_train[val_index]\n",
    "        y_k_train, y_k_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        logistic_model.fit(X_k_train, y_k_train)\n",
    "\n",
    "        y_k_train_pred = logistic_model.predict(X_k_train)\n",
    "        train_accuracy = accuracy_score(y_k_train, y_k_train_pred)\n",
    "        train_precision = precision_score(y_k_train, y_k_train_pred, zero_division=0)\n",
    "        train_recall = recall_score(y_k_train, y_k_train_pred, zero_division=0)\n",
    "        train_f1 = f1_score(y_k_train, y_k_train_pred, zero_division=0)\n",
    "        train_metrics.append([train_accuracy, train_precision, train_recall, train_f1])\n",
    "\n",
    "        y_k_val_pred = logistic_model.predict(X_k_val)\n",
    "        val_accuracy = accuracy_score(y_k_val, y_k_val_pred)\n",
    "        val_precision = precision_score(y_k_val, y_k_val_pred, zero_division=0)\n",
    "        val_recall = recall_score(y_k_val, y_k_val_pred, zero_division=0)\n",
    "        val_f1 = f1_score(y_k_val, y_k_val_pred, zero_division=0)\n",
    "        validation_metrics.append([val_accuracy, val_precision, val_recall, val_f1])\n",
    "\n",
    "    train_metrics_mean = np.mean(train_metrics, axis=0)\n",
    "    validation_metrics_mean = np.mean(validation_metrics, axis=0)\n",
    "\n",
    "    print(f\"K = {k} (Logistic Regression)\")\n",
    "    print(f\"Training Metrics: Accuracy={train_metrics_mean[0]:.2f}, Precision={train_metrics_mean[1]:.2f}, Recall={train_metrics_mean[2]:.2f}, F1-Score={train_metrics_mean[3]:.2f}\")\n",
    "    print(f\"Validation Metrics: Accuracy={validation_metrics_mean[0]:.2f}, Precision={validation_metrics_mean[1]:.2f}, Recall={validation_metrics_mean[2]:.2f}, F1-Score={validation_metrics_mean[3]:.2f}\")\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_test_pred = logistic_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64308e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd1ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics (Logistic Regression):\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.92\n",
      "F1-Score: 0.91\n",
      "\n",
      "Comparison of Perceptron and Logistic Regression:\n",
      "Analyze the training, validation, and test metrics from both models to decide which performs better.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest Set Metrics (Logistic Regression):\")\n",
    "print(f\"Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Precision: {test_precision:.2f}\")\n",
    "print(f\"Recall: {test_recall:.2f}\")\n",
    "print(f\"F1-Score: {test_f1:.2f}\")\n",
    "\n",
    "print(\"\\nComparison of Perceptron and Logistic Regression:\")\n",
    "print(\"Analyze the training, validation, and test metrics from both models to decide which performs better.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9229434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
